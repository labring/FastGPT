---
title: Connect Models via OneAPI
description: Integrate models through OneAPI
---

FastGPT uses a model-separation deployment approach. FastGPT only supports OpenAI's model specification (for non-OpenAI models, it uses a more generic specification) and relies on [One API](https://github.com/songquanpeng/one-api) to unify different model interfaces.

[One API](https://github.com/songquanpeng/one-api) is an OpenAI interface management & distribution system. It lets you access all major LLMs through the standard OpenAI API format, ready to use out of the box.

## FastGPT and One API Relationship

Think of One API as a gateway. The relationship between FastGPT and One API:

![](/imgs/sealos-fastgpt.webp)

## Deployment

### Sealos Version

* Beijing region: [Deploy OneAPI](https://hzh.sealos.run/?openapp=system-template%3FtemplateName%3Done-api)
* Singapore region (GPT available): [Deploy OneAPI](https://cloud.sealos.io/?openapp=system-template%3FtemplateName%3Done-api&uid=fnWRt09fZP)

![alt text](/imgs/image-59.png)

After deployment, open the OneAPI access link to proceed.

## OneAPI Basics

### Concepts

1. **Channel:**
   1. In OneAPI, each channel corresponds to one `API Key`. This key can be from GPT, Microsoft, ChatGLM, Wenxin Yiyan, etc. One `API Key` typically supports multiple models from the same provider.
   2. One API routes requests based on the `model` parameter. If multiple channels support the same model, it randomly selects one.
2. **Token:** The credential needed to access One API. You only need this `1` token to access all models configured in One API. In FastGPT, you only need to configure One API's `baseurl` and `token`. Don't set any model scope restrictions on the token, or you'll get errors.

![alt text](/imgs/image-60.png)

### Basic Workflow

1. Client sends a request to One API
2. One API matches the channel based on the `model` parameter in the request (must match exactly with the channel's model list). If multiple channels match, it randomly selects one (same priority).
3. One API sends the request to the actual endpoint.
4. One API returns the result to the client.

### 1. Log in to One API

![step5](/imgs/oneapi-step5.png)

### 2. Create a Channel

Add the corresponding channel in One API. Click **Add Base Model**. Don't forget to add the embedding model.

![step6](/imgs/oneapi-step6.png)

### 3. Create a Token

| | |
| --- | --- |
| ![step7](/imgs/oneapi-step7.png) | ![alt text](/imgs/image-61.png) |

### 4. Modify Account Balance

One API's default root user has only $200. You can edit this yourself.

![alt text](/imgs/image-62.png)

### 5. Update FastGPT Environment Variables

Once you have the One API token, FastGPT can request One API by modifying the `baseurl` and `key`, and One API will route to different models. Update these two environment variables:

```bash
# Must include v1. If on the same network, you can use an internal address.
OPENAI_BASE_URL=https://xxxx.cloud.sealos.io/v1
# The key below is the token provided by One API
CHAT_API_KEY=sk-xxxxxx
```

## Integrating Other Models

**Example: Adding Wenxin Yiyan (Baidu ERNIE):**

### 1. Add Model Channel in OneAPI

Select Baidu Wenxin Qianfan as the type.

![](/imgs/oneapi-demo1.png)

### 2. Update FastGPT Model Configuration

Open FastGPT model configuration and enable the Wenxin Qianfan model. If it's not built-in, you can add it as a custom model.

![alt text](/imgs/image-103.png)

## Other Provider Integration Examples

This section covers tutorials for integrating various providers into OneAPI. Don't forget to enable them in FastGPT's model configuration after setup.

### Alibaba Tongyi Qianwen

Qianwen now supports GPT format, so you can directly select the OpenAI type for integration. As shown below, select `OpenAI` as the type and enter Alibaba Cloud's proxy address.

You can directly use Alibaba Cloud's language models and the `text-embedding-v3` embedding model (tested and confirmed to be normalized, ready to use).

![alt text](/imgs/image-63.png)

### SiliconCloud â€” Open-Source Model Collection

[SiliconCloud](https://cloud.siliconflow.cn/i/TR9Ym0c4) is a platform dedicated to providing open-source model APIs with its own acceleration engine. It has broad model coverage and is ideal for low-cost testing of open-source models. Integration tutorial:

1. [Register for a SiliconCloud account](https://cloud.siliconflow.cn/i/TR9Ym0c4)
2. Go to the console and get your API key: https://cloud.siliconflow.cn/account/ak
3. Add a OneAPI channel, select `OpenAI` type, enter proxy: `https://api.siliconflow.cn`, and use the key from step 2.

![alt text](/imgs/image-64.png)

Since OneAPI doesn't have SiliconCloud model names built-in, you can add them via custom model names. Here's how to get the model names:

1. Open the [SiliconCloud model list](https://siliconflow.cn/zh-cn/models)
2. Click on a model to open its details.
3. Copy the model name to OneAPI.

| | | |
| --- | --- | --- |
| ![alt text](/imgs/image-65.png) | ![alt text](/imgs/image-66.png)| ![alt text](/imgs/image-67.png) |
