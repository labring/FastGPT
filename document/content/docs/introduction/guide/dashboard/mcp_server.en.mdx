---
title: MCP Server
description: Quick guide to FastGPT MCP server
---

## MCP Server Introduction

MCP (Model Context Protocol) was released by Anthropic in early November 2024. Its purpose is to standardize communication between AI models and external systems, simplifying integration challenges. With OpenAI's official support for MCP, more AI vendors are adopting the protocol.

MCP consists of two main parts: Client and Server. Simply put, the Client uses the AI model and provides it with capabilities to call external systems through MCP Client; the Server provides external system calls and actually runs those external systems.

FastGPT's MCP Server feature lets you select `multiple` applications built on FastGPT and expose them via MCP protocol for external calls.

Currently, FastGPT's MCP server uses SSE communication protocol, which will be replaced with `HTTP streamable` in the future.

## Using MCP Server in FastGPT

### 1. Create MCP Server

After logging into FastGPT, open `Workspace`, click `MCP server` to enter the management page where you can see all your created MCP servers and the number of applications they manage.

![Create MCP server](/imgs/mcp_server1.png)

You can customize the MCP server name and select associated applications.

| | |
|---|---|\n| ![](/imgs/mcp_server2.png) | ![](/imgs/mcp_server3.png) |

### 2. Get MCP Server Address

After creating the MCP server, click `Start Using` to get the MCP server access address.

| | |
|---|---|
| ![](/imgs/mcp_server4.png) | ![](/imgs/mcp_server5.png) |

#### 3. Use MCP Server

You can use these addresses in MCP-compatible clients to call FastGPT applications, such as: `Cursor`, `Cherry Studio`. Below is an example using Cursor.

Open Cursor's settings page, click MCP to enter the MCP configuration page. Click the new MCP server button, which opens a JSON configuration file. Copy the `integration script` from step 2 into the `JSON file` and save.

Return to Cursor's MCP management page to see your created MCP server. Remember to set it to `enabled` status.

| | | |
|---|---|---|
| ![](/imgs/mcp_server6.png) | ![](/imgs/mcp_server7.png) | ![](/imgs/mcp_server8.png) |

Open Cursor's chat box and switch to `Agent` model â€” only this model will call MCP server.  
After sending a question about `fastgpt`, you'll see Cursor call an MCP tool (described as: query fastgpt knowledge base), which calls the FastGPT application to process the question and return results.

| | |
|---|---|
| ![](/imgs/mcp_server9.png) | ![](/imgs/mcp_server10.png) |

## Self-Hosted MCP Server Issues

Self-hosted FastGPT deployments need to upgrade to `v4.9.6` or higher to use MCP server functionality.

### Modify docker-compose.yml File

In the `docker-compose.yml` file, add the `fastgpt-mcp-server` service:

```yml
fastgpt-mcp-server:
    container_name: fastgpt-mcp-server
    image: ghcr.io/labring/fastgpt-mcp_server:latest
    ports:
      - 3005:3000
    networks:
      - fastgpt
    restart: always
    environment:
      - FASTGPT_ENDPOINT=http://fastgpt:3000
```

### Modify FastGPT Container Environment Variables

Modify the `config.json` configuration file, add: `"feconfigs.mcpServerProxyEndpoint": "fastgpt-mcp-server access address"`, without trailing /, for example:
```json
{
  "feConfigs": {
    "lafEnv": "https://laf.dev",
    "mcpServerProxyEndpoint": "https://mcp.fastgpt.cn" 
  }
}
```

### Restart FastGPT Container

Since you modified mounted files, you can force down then up the service. After starting, you'll see the MCP server service option in the workspace.

```bash
docker-compose down
docker-compose up -d
```
