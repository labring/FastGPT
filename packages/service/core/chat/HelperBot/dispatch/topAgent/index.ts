import type { HelperBotDispatchParamsType, HelperBotDispatchResponseType } from '../type';
import { helperChats2GPTMessages } from '@fastgpt/global/core/chat/helperBot/adaptor';
import { getPrompt } from './prompt';
import { createLLMResponse } from '../../../../ai/llm/request';
import { getLLMModel } from '../../../../ai/model';
import { SseResponseEventEnum } from '@fastgpt/global/core/workflow/runtime/constants';
import { textAdaptGptResponse } from '@fastgpt/global/core/workflow/runtime/utils';
import type { AIChatItemValueItemType } from '@fastgpt/global/core/chat/helperBot/type';
import { getSystemToolsWithInstalled } from '../../../../app/tool/controller';

export const dispatchTopAgent = async (
  props: HelperBotDispatchParamsType
): Promise<HelperBotDispatchResponseType> => {
  const { query, files, metadata, histories, workflowResponseWrite, teamId, userId } = props;

  // 1. è·å– LLM æ¨¡å‹é…ç½® (ä¼˜å…ˆä½¿ç”¨å‰ç«¯ä¼ å…¥çš„ modelConfigï¼Œå¦åˆ™ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ¨¡å‹)
  const modelConfig = metadata.data?.modelConfig;

  const modelName = modelConfig?.model || global.systemDefaultModel?.llm?.model;
  if (!modelName) {
    throw new Error('æœªé…ç½® LLM æ¨¡å‹ï¼Œè¯·åœ¨å‰ç«¯é€‰æ‹©æ¨¡å‹æˆ–åœ¨ç³»ç»Ÿä¸­é…ç½®é»˜è®¤æ¨¡å‹');
  }
  const modelData = getLLMModel(modelName);
  if (!modelData) {
    throw new Error(`æ¨¡å‹ ${modelName} æœªæ‰¾åˆ°`);
  }

  // è·å–æ¨¡å‹å‚æ•° (ä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼)
  const temperature = modelConfig?.temperature ?? 0.7;
  const maxToken = modelConfig?.maxToken ?? 4000;
  const stream = modelConfig?.stream ?? true;

  console.log(
    `ğŸ¤– TopAgent ä½¿ç”¨æ¨¡å‹: ${modelName}, temperature: ${temperature}, maxToken: ${maxToken}`
  );

  // 2. ç”Ÿæˆèµ„æºåˆ—è¡¨ - ä»æ•°æ®åº“æŸ¥è¯¢æ‰€æœ‰å·²å®‰è£…çš„å·¥å…·å’ŒçŸ¥è¯†åº“
  const resourceList = await generateResourceList({
    teamId,
    userId
  });

  // 3. æ„å»ºæ¶ˆæ¯
  const historyMessages = helperChats2GPTMessages({
    messages: histories,
    reserveTool: false
  });

  const systemPrompt = getPrompt({ resourceList });
  const conversationMessages = [
    { role: 'system' as const, content: systemPrompt },
    ...historyMessages,
    { role: 'user' as const, content: query }
  ];

  // 4. è°ƒç”¨ LLM (ç¬¬ä¸€é˜¶æ®µ: ä¿¡æ¯æ”¶é›†)
  console.log('ğŸ“ TopAgent é˜¶æ®µ 1: ä¿¡æ¯æ”¶é›†');
  console.log('conversationMessages:', conversationMessages);

  const llmResponse = await createLLMResponse({
    body: {
      messages: conversationMessages,
      model: modelName,
      temperature,
      stream,
      max_tokens: maxToken
    },
    onStreaming: ({ text }) => {
      workflowResponseWrite?.({
        event: SseResponseEventEnum.answer,
        data: textAdaptGptResponse({ text })
      });
    },
    onReasoning: ({ text }) => {
      workflowResponseWrite?.({
        event: SseResponseEventEnum.answer,
        data: textAdaptGptResponse({ reasoning_content: text })
      });
    }
  });

  const firstPhaseAnswer = llmResponse.answerText;
  const firstPhaseReasoning = llmResponse.reasoningText;
  console.log('FirstPhaseAnswer:', firstPhaseAnswer);
  console.log('FirstPhaseReasoning:', firstPhaseReasoning);
  // 5. æ£€æµ‹é˜¶æ®µåˆ‡æ¢ä¿¡å·
  if (firstPhaseAnswer.includes('ã€Œä¿¡æ¯æ”¶é›†å·²å®Œæˆã€')) {
    console.log('ğŸ”„ TopAgent: æ£€æµ‹åˆ°ä¿¡æ¯æ”¶é›†å®Œæˆä¿¡å·ï¼Œåˆ‡æ¢åˆ°è®¡åˆ’ç”Ÿæˆé˜¶æ®µ');

    // æ„å»ºæ–°çš„æ¶ˆæ¯å†å²
    const newMessages = [
      ...conversationMessages,
      { role: 'assistant' as const, content: firstPhaseAnswer },
      { role: 'user' as const, content: 'è¯·ä½ ç›´æ¥ç”Ÿæˆè§„åˆ’æ–¹æ¡ˆ' }
    ];

    // ç¬¬äºŒæ¬¡è°ƒç”¨ LLM (ç¬¬äºŒé˜¶æ®µ: è®¡åˆ’ç”Ÿæˆ)
    console.log('ğŸ“‹ TopAgent é˜¶æ®µ 2: è®¡åˆ’ç”Ÿæˆ');

    const planResponse = await createLLMResponse({
      body: {
        messages: newMessages,
        model: modelName,
        temperature,
        stream,
        max_tokens: maxToken
      },
      onStreaming: ({ text }) => {
        workflowResponseWrite?.({
          event: SseResponseEventEnum.answer,
          data: textAdaptGptResponse({ text })
        });
      },
      onReasoning: ({ text }) => {
        workflowResponseWrite?.({
          event: SseResponseEventEnum.answer,
          data: textAdaptGptResponse({ reasoning_content: text })
        });
      }
    });

    console.log('âœ… TopAgent: è®¡åˆ’ç”Ÿæˆå®Œæˆ');

    // è§£æè®¡åˆ’ JSON,æå–è¡¨å•æ•°æ®
    let formData;
    try {
      const planJson = JSON.parse(planResponse.answerText);
      console.log('è§£æçš„è®¡åˆ’ JSON:', planJson);

      formData = {
        role: planJson.task_analysis?.role || '',
        taskObject: planJson.task_analysis?.goal || '',
        tools: planJson.resources?.tools?.map((tool: any) => tool.id) || [],
        fileUploadEnabled: planJson.resources?.system_features?.file_upload?.enabled || false
      };
      console.log('æå–çš„è¡¨å•æ•°æ®:', formData);
    } catch (e) {
      console.error('è§£æè®¡åˆ’ JSON å¤±è´¥:', e);
    }

    // è¿”å›è®¡åˆ’ç”Ÿæˆé˜¶æ®µçš„å“åº” - åŒ…å«è¡¨å•æ•°æ®
    return {
      aiResponse: formatAIResponse(planResponse.answerText, planResponse.reasoningText),
      formData
    };
  }

  // 6. è¿”å›ä¿¡æ¯æ”¶é›†é˜¶æ®µçš„å“åº” - ä¸åŒ…å«è¡¨å•æ•°æ®
  console.log('âœ… TopAgent: ä¿¡æ¯æ”¶é›†å®Œæˆï¼Œç­‰å¾…ä¸‹ä¸€è½®');

  return {
    aiResponse: formatAIResponse(firstPhaseAnswer, firstPhaseReasoning)
  };
};

const generateResourceList = async ({
  teamId,
  userId
}: {
  teamId: string;
  userId: string;
}): Promise<string> => {
  let result = '\n## å¯ç”¨èµ„æºåˆ—è¡¨\n';

  const tools = await getSystemToolsWithInstalled({
    teamId,
    isRoot: true // TODO: éœ€è¦ä¼ å…¥å®é™…çš„ isRoot å€¼
  });

  const installedTools = tools.filter((tool) => {
    return tool.installed && !tool.isFolder;
  });

  if (installedTools.length > 0) {
    result += '### å·¥å…·\n';
    installedTools.forEach((tool) => {
      const toolId = tool.id;
      const name =
        typeof tool.name === 'string'
          ? tool.name
          : tool.name?.en || tool.name?.['zh-CN'] || 'æœªå‘½å';
      const intro =
        typeof tool.intro === 'string' ? tool.intro : tool.intro?.en || tool.intro?.['zh-CN'] || '';
      const description = tool.toolDescription || intro || 'æš‚æ— æè¿°';
      result += `- **${toolId}** [å·¥å…·]: ${name} - ${description}\n`;
    });
  } else {
    result += '### å·¥å…·\næš‚æ— å·²å®‰è£…çš„å·¥å…·\n';
  }

  // TODO: çŸ¥è¯†åº“
  result += '\n### çŸ¥è¯†åº“\næš‚æœªé…ç½®çŸ¥è¯†åº“\n';

  result += '\n### ç³»ç»ŸåŠŸèƒ½\n';
  result += '- **file_upload**: æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ (enabled, purpose, file_types)\n';

  return result;
};

const formatAIResponse = (text: string, reasoning?: string): AIChatItemValueItemType[] => {
  const result: AIChatItemValueItemType[] = [];

  if (reasoning) {
    result.push({
      reasoning: {
        content: reasoning
      }
    });
  }

  result.push({
    text: {
      content: text
    }
  });

  return result;
};
