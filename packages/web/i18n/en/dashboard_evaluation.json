{
  "Action": "Operation",
  "Evaluation_app": "App",
  "Evaluation_app_tip": "You can select a simple app or a workflow without user interaction nodes. Plugins are not supported.",
  "Evaluation_file": "Evaluation file",
  "Evaluation_model": "Evaluation model",
  "Executor": "Operator",
  "Overall_score": "Score",
  "Progress": "Progress",
  "Start_end_time": "Start/End Time",
  "Task_name_placeholder": "Please enter a task name",
  "answer": "Standard answer",
  "app_required": "Select",
  "app_response": "App output",
  "back": "Exit",
  "check_error": "Verification failed.",
  "check_error_tip": "Please check the following:\n1. Headers in the file must be consistent with those in the CSV template.\n2. All required fields are configured.\n3. Global variables are valid.\n4. Numeric input boxes contain valid numbers.\n5. Radio button options are valid.",
  "check_format": "Format verification",
  "comfirm_delete_item": "Are you sure you want to delete this entry?",
  "comfirm_delete_task": "Are you sure you want to delete this task and all related data?",
  "completed": "Completed",
  "create_task": "Create task",
  "data": "Data",
  "data_list": "Details",
  "detail": "Details",
  "error": "Abnormal",
  "error_tooltip": "Abnormal task detected.\nClick to view task details.",
  "eval_file_check_error": "Failed to verify the evaluation file.",
  "evaluating": "Evaluating",
  "evaluation": "App evaluation",
  "evaluation_export_title": "Question, Standard answer, Actual answer, Status, Score",
  "evaluation_file_max_size": "Entries: {{count}}",
  "export": "Export",
  "file_required": "Select",
  "file_uploading": "Uploading file: {{num}}%",
  "history": "History",
  "paused": "Paused",
  "question": "Question",
  "queuing": "Waiting",
  "search_task": "Search task",
  "standard_response": "Standard output",
  "start_evaluation": "Evaluate",
  "stauts": "Status",
  "task_creating": "Creating task",
  "task_detail": "Task details",
  "task_name": "Task name",
  "team_has_running_evaluation": "The team already has an app evaluation task in progress. Please wait until it is complete.",
  "template_csv_file_select_tip": "Must be a {{fileType}} file <highlight>strictly consistent with the template</highlight>.",
  "variables": "Global variables",
  "all_apps": "All apps",
  "search_evaluation_task": "Task name, app version",
  "create_new_task": "Create task",
  "task_name_column": "Task name",
  "progress_column": "Progress",
  "evaluation_app_column": "App",
  "app_version_column": "App version",
  "evaluation_result_column": "Evaluation result",
  "start_finish_time_column": "Time started/completed",
  "executor_column": "Operator",
  "waiting": "Waiting",
  "evaluating_status": "Evaluating",
  "completed_status": "Completed",
  "queuing_status": "Waiting",
  "running_status": "Ongoing",
  "error_data_tooltip": "{{count}} entries encountered execution error. Click to view error details.",
  "rename": "Rename",
  "delete": "Delete",
  "confirm_delete_task": "Are you sure you want to delete this task?",
  "evaluation_tasks_tab": "Tasks",
  "evaluation_tasks": "Evaluation tasks",
  "evaluation_datasets_tab": "Datasets",
  "evaluation_dimensions_tab": "Metrics",
  "create_new": "New",
  "retry_error_data": "Retry failed entries",
  "dataset_name_placeholder": "Name",
  "create_new_dataset": "Create dataset",
  "smart_generation": "Auto generate",
  "file_import": "Import from file",
  "confirm_delete_dataset": "Are you sure you want to delete this dataset?",
  "error_details": "Details",
  "status_queuing": "Waiting",
  "status_parsing": "Parsing file",
  "status_generating": "Generating data",
  "status_generate_error": "Generation error",
  "status_ready": "Ready",
  "status_parse_error": "Parsing error",
  "click_to_view_details": "View details",
  "table_header_name": "Name",
  "table_header_data_count": "Data size",
  "table_header_time": "Time created/updated",
  "table_header_status": "Status",
  "table_header_creator": "Creator",
  "create_dimension": "Add metric",
  "search_dimension": "Metric",
  "delete_failed": "Operation failed.",
  "delete_success": "Deleted successfully.",
  "builtin": "Predefined",
  "confirm_delete_dimension": "Are you sure that you want to delete this metric?",
  "dimension_name": "Metric name",
  "description": "Description",
  "create_update_time": "Time created/updated",
  "creator": "Creator",
  "all": "All",
  "app": "App",
  "citation_template": "Template",
  "correctness": "Correctness",
  "conciseness": "Conciseness",
  "harmfulness": "Harmfulness",
  "controversiality": "Controversiality",
  "creativity": "Creativity",
  "criminality": "Criminality",
  "depth": "Depth",
  "details": "Details",
  "dimension_name_label": "Metric name",
  "dimension_description_label": "Metric description",
  "prompt_label": "Prompt",
  "citation_template_button": "Template",
  "test_run_title": "Trial run",
  "question_label": "Question",
  "question_placeholder": " ",
  "answer_label": "Answer",
  "reference_answer_label": "Answer for reference",
  "reference_answer_placeholder": " ",
  "actual_answer_label": "Actual answer",
  "actual_answer_placeholder": " ",
  "run_result_label": "Running result",
  "start_run_button": "Run",
  "running_text": "Running",
  "run_success": "Run successful",
  "run_failed": "Run failed",
  "not_run": "Not run",
  "score_unit": "(Score)",
  "error_info_label": "Error message: ",
  "no_feedback_text": "No feedback available.",
  "dimension_create_back": "Exit",
  "dimension_create_test_run": "Trial run",
  "dimension_create_confirm": "OK",
  "dimension_create_success": "Created successfully.",
  "dimension_create_name_required": "Name is required.",
  "dimension_create_prompt_required": "Prompt is required.",
  "dimension_get_data_failed": "Failed to obtain the metric data.",
  "dimension_data_not_exist": "The metric data does not exist.",
  "dimension_update_success": "Update successful.",
  "dimension_update_failed": "Update failed.",
  "dimension_name_required": "Name is required.",
  "dimension_back": "Exit",
  "dimension_test_run": "Trial run",
  "dimension_save": "Save",
  "file_import_back": "Exit",
  "file_import_name_label": "Name",
  "file_import_name_placeholder": " ",
  "file_import_select_file": "Please select a file.",
  "file_import_success": "File imported successfully.",
  "file_import_file_label": "File",
  "file_import_download_template": "Download template",
  "file_import_download_template_tip": "Download the template to see the required file format.",
  "file_import_auto_evaluation_label": "Automatically evaluate the quality of imported data",
  "file_import_auto_evaluation_tip": "If enabled, a quality evaluation will be automatically performed on the imported data.",
  "file_import_evaluation_model_label": "Quality evaluation model",
  "file_import_evaluation_model_placeholder": "Select",
  "file_import_confirm": "OK",
  "manage_dimension": "Manage metrics",
  "selected_count": "Selected",
  "dimension_config_tip": "Dimension configuration instructions",
  "custom": "Custom",
  "select_model_placeholder": "Select",
  "create_new_task_modal": "Create task",
  "task_name_input": "Task name",
  "task_name_input_placeholder": " ",
  "evaluation_app_select": "App",
  "evaluation_app_support_tip": "You can select a simple app or workflow but cannot select a plugin.",
  "evaluation_app_select_placeholder": "Select",
  "evaluation_app_version_select": "App version",
  "evaluation_app_version_select_placeholder": "Select",
  "evaluation_dataset_select": "Dataset",
  "evaluation_dataset_select_placeholder": "Select",
  "create_import_dataset": "Create/Import",
  "evaluation_dimensions_label": "Metrics",
  "evaluation_dimensions_recommendation": "The evaluation involves knowledge base searches and AI chats. It is recommended to use {{num}} metrics for evaluation.",
  "builtin_dimension": "Predefined",
  "custom_dimension": "Custom",
  "config_params": "Settings",
  "score_aggregation_method": "Score aggregation",
  "score_aggregation_method_tip": "Select a method to aggregate the scores for multiple metrics.",
  "evaluation_dimensions": "Metrics",
  "dimension": "Metric",
  "judgment_threshold": "Threshold",
  "judgment_threshold_tip": "Used to determine whether the score for a metric meets expectations. If the score is lower than the specified threshold, it will be marked as lower-than-expected. Valid value: 1-100 After the evaluation is complete, you can adjust the values as needed.",
  "comprehensive_score_weight": "Weight",
  "comprehensive_score_weight_tip": "The proportion of a metric's score to the total score. You can configure it as needed. After the evaluation is complete, you can adjust the values as needed.",
  "comprehensive_score_weight_sum": "Total weight:",
  "intelligent_generation_dataset": "Auto generate dataset",
  "dataset_name_input": "Name",
  "dataset_name_input_placeholder": "Dataset name",
  "generation_basis": "Data source",
  "select_knowledge_base": "Select knowledge base",
  "data_amount": "Data size",
  "generation_model": "Model",
  "generation_model_placeholder": "Select",
  "high_quality": "High quality",
  "needs_improvement": "Pending optimization",
  "detail_evaluating": "Evaluating",
  "abnormal": "Evaluation error",
  "not_evaluated": "Not evaluated",
  "modify_result": "Modify",
  "restart_evaluation": "Evaluate again",
  "evaluation_error_message": "Error occurred during the evaluation. Please try again.",
  "high_quality_feedback": "The question is complete, clear, and accurate, meeting the standard. The answer is accurate and practical.",
  "needs_improvement_feedback": "The question needs to be optimized. To obtain a more accurate answer, please provide more context to make the question more specific and accurate.",
  "evaluation_service_error": "Evaluation service error.",
  "edit_data": "Edit data",
  "enter_question": "This field is required.",
  "question_required": "Question is required.",
  "reference_answer": "Answer for reference",
  "enter_reference_answer": "This field is required.",
  "reference_answer_required": "Answer for reference is required.",
  "quality_evaluation": "Quality evaluation",
  "cancel": "Cancel",
  "save": "Save",
  "save_and_next": "Save and proceed",
  "manually_calibrated": "Manually modified",
  "modify_evaluation_result_title": "Modify result",
  "evaluation_result_label": "Evaluation result",
  "modify_reason_label": "Modification cause",
  "modify_reason_input_placeholder": " ",
  "no_data": "No data available.",
  "search": "Search",
  "settings": "Settings",
  "add_data": "Add data",
  "ai_generate": "Auto generate",
  "manual_add": "Manually add",
  "no_answer": "No answers available.",
  "confirm_delete_data": "Are you sure you want to delete this entry?",
  "no_evaluation_result_click": "No evaluation results available. Click to ",
  "start_evaluation_action": "start evaluation.",
  "evaluation_dataset": "Dataset",
  "evaluation_status": "Status",
  "manually_add_data_modal": "手动新增数据",
  "question_input_label": "问题",
  "max_chars_3000_placeholder": "最多 3000 字",
  "reference_answer_input_label": "参考答案",
  "auto_quality_eval_after_add": "数据质量评测",
  "auto_quality_eval_add_tip": "开启后，将自动对数据的问答相关度、合理性等进行评测，给出数据质量评价及原因，可根据评价对数据进行优化。",
  "quality_eval_model_label": "质量评测模型",
  "select_quality_eval_model_placeholder": "请选择质量评测模型",
  "confirm": "确认",
  "confirm_quality_evaluation": "确认对全部数据（{{total}}）进行质量评测吗？",
  "model_change_notice": "更改模型后将对后续评测的任务生效。",
  "evaluation_model": "评测模型",
  "select_evaluation_model": "请选择评测模型",
  "evaluation_abnormal": "评测异常",
  "error_message": "报错信息",
  "file_parse_error": "文件解析异常",
  "delete_file": "删除文件",
  "reparse": "重新解析",
  "data_generation_error": "条数据生成异常",
  "source_knowledge_base": "依据知识库",
  "source_chunk": "依据分块",
  "operations": "操作",
  "retry": "重试",
  "retry_all": "全部重试",
  "error_info": "异常信息",
  "manual_add_data": "手动新增数据",
  "max_3000_chars": "最多 3000 字",
  "please_enter_question": "请输入问题",
  "question_max_3000_chars": "问题不能超过3000字",
  "please_enter_reference_answer": "请输入参考答案",
  "reference_answer_max_3000_chars": "参考答案不能超过3000字",
  "auto_quality_evaluation": "新增后自动进行数据质量评测",
  "quality_evaluation_tip": "将对数据的问答相关度、合理性等进行评测，给出数据质量评价及原因，可根据评价对数据进行优化。",
  "quality_evaluation_model": "质量评测模型",
  "please_select_evaluation_model": "请选择质量评测模型",
  "summary_pending": "Pending",
  "summary_generating": "Generating",
  "summary_done": "Completed",
  "summary_failed": "Failed",
  "method_mean": "Mean",
  "method_median": "Median",
  "prompt_cannot_be_empty": "提示词不允许为空",
  "please_select_model": "请选择模型",
  "run_failed_please_retry": "运行失败，请重试",
  "intelligent_generate_data": "智能生成数据",
  "evaluation_completed": "评估完成",
  "generation_error": "生成异常",
  "data_generating": "数据生成中",
  "delete_dataset_error": "删除数据集异常",
  "create_failed": "创建失败",
  "no_dimension_data": "暂无维度数据",
  "please_select_dimension_first": "请先选择该维度",
  "model_evaluation_tip": "语言模型可判断实际回答和参考答案中的文本内容是否匹配；\n索引模型可将实际回答和参考答案转成向量，进一步评估语义相似性。",
  "create_new_dimension": "新建维度",
  "retry_success": "重试成功",
  "data_generation_error_count": "{{count}}条数据生成异常",
  "builtin_answer_correctness_name": "Answer Correctness",
  "builtin_answer_correctness_desc": "Evaluates the factual consistency between the generated answer and the reference answer, evaluating whether it is accurate and error-free.",
  "builtin_answer_similarity_name": "Answer Similarity",
  "builtin_answer_similarity_desc": "Evaluates the semantic alignment between the generated answer and the reference answer, determining whether they convey the same core information.",
  "builtin_answer_relevancy_name": "Answer Relevance",
  "builtin_answer_relevancy_desc": "Evaluates how well the generated answer aligns with the question, judging whether the response directly addresses the query.",
  "builtin_faithfulness_name": "Faithfulness",
  "builtin_faithfulness_desc": "Evaluates whether the generated answer remains faithful to the provided context, determining whether it contains fabricated or inaccurate content.",
  "builtin_context_recall_name": "Context Recall",
  "builtin_context_recall_desc": "Evaluates whether the retrieval system successfully retrieves all key information necessary for formulating the answer, assessing the completeness of retrieval.",
  "builtin_context_precision_name": "Context Precision",
  "builtin_context_precision_desc": "Evaluates whether high-value information is prioritized in the retrieved content, reflecting the quality of ranking and information density.",
  "join_evaluation_dataset": "加入评测数据集",
  "not_join_evaluation_dataset": "不加入评测数据集",
  "create_new_dataset_btn_text": "新建数据集",
  "please_select_evaluation_dataset": "请选择评测数据集",
  "join_knowledge_base": "加入知识库"
}
