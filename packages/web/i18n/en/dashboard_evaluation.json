{
  "Action": "Operation",
  "Evaluation_app": "App",
  "Evaluation_app_tip": "Supports a simple app or a workflow without user interaction nodes. Plugins are not supported.",
  "Evaluation_file": "File",
  "Evaluation_model": "Model",
  "Executor": "Operator",
  "Overall_score": "Score",
  "Progress": "Progress",
  "Start_end_time": "Start/End Time",
  "Task_name_placeholder": "",
  "answer": "Standard answer",
  "app_required": "Please select an app first.",
  "app_response": "App output",
  "back": "Exit",
  "check_error": "Verification failed.",
  "check_error_tip": "Please check the following:\n1. Headers in the file must be consistent with those in the CSV template.\n2. All required fields are configured.\n3. Global variables are valid.\n4. Numeric input boxes contain valid numbers.\n5. Radio button options are valid.",
  "check_format": "Format verification",
  "comfirm_delete_item": "Are you sure you want to delete this entry?",
  "comfirm_delete_task": "Are you sure you want to delete this task and all related data?",
  "completed": "Completed",
  "create_task": "Create task",
  "data": "Data",
  "data_list": "Details",
  "detail": "Details",
  "error": "Error",
  "error_tooltip": "A task encountered error.\nClick to view task details.",
  "eval_file_check_error": "Evaluation file verification failed.",
  "evaluating": "Evaluating",
  "evaluation": "App evaluation",
  "evaluation_export_title": "Question,Standard answer,Actual answer,Status,Score",
  "evaluation_file_max_size": "Entries: {{count}}",
  "export": "Export",
  "file_required": "Select",
  "file_uploading": "Uploading file: {{num}}%",
  "history": "History",
  "paused": "Paused",
  "question": "Question",
  "queuing": "Waiting",
  "search_task": "Task",
  "standard_response": "Standard output",
  "start_evaluation": "Evaluate",
  "stauts": "Status",
  "task_creating": "Creating task",
  "task_detail": "Task details",
  "task_name": "Task name",
  "team_has_running_evaluation": "An app evaluation task is in progress. Please wait until it is complete.",
  "template_csv_file_select_tip": "Must be a {{fileType}} file that <highlight>strictly follows the template</highlight>.",
  "variables": "Global variables",
  "all_apps": "All apps",
  "search_evaluation_task": "Task name, app version",
  "create_new_task": "Create task",
  "task_name_column": "Task name",
  "progress_column": "Progress",
  "evaluation_app_column": "App",
  "app_version_column": "App version",
  "evaluation_result_column": "Evaluation result",
  "start_finish_time_column": "Time started/completed",
  "executor_column": "Operator",
  "waiting": "Waiting",
  "evaluating_status": "Evaluating",
  "completed_status": "Completed",
  "queuing_status": "Waiting",
  "running_status": "Ongoing",
  "error_data_tooltip": "{{count}} entries encountered execution error. Click to view error details.",
  "rename": "Rename",
  "delete": "Delete",
  "confirm_delete_task": "Are you sure you want to delete this task?",
  "evaluation_tasks_tab": "Tasks",
  "evaluation_tasks": "Evaluation tasks",
  "evaluation_datasets_tab": "Datasets",
  "evaluation_dimensions_tab": "Metrics",
  "create_new": "Create",
  "retry_error_data": "Retry failed entries",
  "dataset_name_placeholder": "Name",
  "create_new_dataset": "Create",
  "smart_generation": "Auto generate",
  "file_import": "Import from file",
  "confirm_delete_dataset": "Are you sure you want to delete this dataset?",
  "error_details": "Details",
  "status_queuing": "Waiting",
  "status_parsing": "Parsing file",
  "status_generating": "Generating data",
  "status_generate_error": "Generation error",
  "status_ready": "Ready",
  "status_parse_error": "Parsing error",
  "click_to_view_details": "View details",
  "table_header_name": "Name",
  "table_header_data_count": "Data size",
  "table_header_time": "Time created/updated",
  "table_header_status": "Status",
  "table_header_creator": "Creator",
  "create_dimension": "Create",
  "search_dimension": "Metric",
  "delete_failed": "Operation failed.",
  "delete_success": "Deleted successfully.",
  "builtin": "Predefined",
  "confirm_delete_dimension": "Are you sure that you want to delete this metric?",
  "dimension_name": "Name",
  "description": "Description",
  "create_update_time": "Time created/updated",
  "creator": "Creator",
  "all": "All",
  "app": "App",
  "citation_template": "Template",
  "correctness": "Correctness",
  "conciseness": "Conciseness",
  "harmfulness": "Harmfulness",
  "controversiality": "Controversiality",
  "creativity": "Creativity",
  "criminality": "Criminality",
  "depth": "Depth",
  "details": "Detail",
  "dimension_name_label": "Name",
  "dimension_description_label": "Description",
  "prompt_label": "Prompt",
  "citation_template_button": "Template",
  "test_run_title": "Trial run",
  "question_label": "Question",
  "question_placeholder": "",
  "answer_label": "Answer",
  "reference_answer_label": "Answer for reference",
  "reference_answer_placeholder": "",
  "actual_answer_label": "Actual answer",
  "actual_answer_placeholder": "",
  "run_result_label": "Running result",
  "start_run_button": "Run",
  "running_text": "Running",
  "run_success": "Run successful",
  "run_failed": "Run failed",
  "not_run": "Not run",
  "score_unit": "(Score)",
  "error_info_label": "Error: ",
  "no_feedback_text": "No feedback available.",
  "dimension_create_back": "Exit",
  "dimension_create_test_run": "Trial run",
  "dimension_create_confirm": "OK",
  "dimension_create_success": "Created successfully.",
  "dimension_create_name_required": "Name is required.",
  "dimension_create_prompt_required": "Prompt is required.",
  "dimension_get_data_failed": "Failed to obtain the metric data.",
  "dimension_data_not_exist": "The metric data does not exist.",
  "dimension_update_success": "Update successful.",
  "dimension_update_failed": "Update failed.",
  "dimension_name_required": "Name is required.",
  "dimension_back": "Exit",
  "dimension_test_run": "Trial run",
  "dimension_save": "Save",
  "file_import_back": "Exit",
  "file_import_name_label": "Dataset name",
  "file_import_name_placeholder": "",
  "file_import_select_file": "Please select a file.",
  "file_import_success": "File imported successfully.",
  "file_import_file_label": "File",
  "file_import_download_template": "Download template",
  "file_import_download_template_tip": "Download the template to see the required file format.",
  "file_import_auto_evaluation_label": "Automatically evaluate the quality of imported data",
  "file_import_auto_evaluation_tip": "If enabled, a quality evaluation will be automatically performed on the imported data.",
  "file_import_evaluation_model_label": "Evaluation model",
  "file_import_evaluation_model_placeholder": "Select",
  "file_import_confirm": "OK",
  "manage_dimension": "Settings",
  "selected_count": "Selected",
  "dimension_config_tip": "Dimension configuration instructions",
  "custom": "Custom",
  "select_model_placeholder": "Select",
  "create_new_task_modal": "Create task",
  "task_name_input": "Name",
  "task_name_input_placeholder": "",
  "evaluation_app_select": "App",
  "evaluation_app_support_tip": "You can select a simple app or workflow but not a plugin.",
  "evaluation_app_select_placeholder": "Select",
  "evaluation_app_version_select": "App version",
  "evaluation_app_version_select_placeholder": "Select",
  "evaluation_dataset_select": "Dataset",
  "evaluation_dataset_select_placeholder": "Select",
  "create_import_dataset": "Create/Import",
  "evaluation_dimensions_label": "Metrics",
  "evaluation_dimensions_recommendation": "The evaluation involves knowledge base queries and AI chats. It is recommended to use {{num}} metrics for evaluation.",
  "builtin_dimension": "Predefined",
  "custom_dimension": "Custom",
  "config_params": "Settings",
  "score_aggregation_method": "Score aggregation",
  "score_aggregation_method_tip": "Select a method to aggregate the scores for multiple metrics.",
  "evaluation_dimensions": "Metrics",
  "dimension": "Metric",
  "judgment_threshold": "Threshold",
  "judgment_threshold_tip": "Determines whether a metric's score meets expectations. If it is lower than the specified threshold, it will be marked as Below expectation. Valid range: 1-100. After the evaluation is complete, you can adjust it as needed.",
  "comprehensive_score_weight": "Weight",
  "comprehensive_score_weight_tip": "The ration of a metric's score to the total score. You can configure it as needed. After the evaluation is complete, you can adjust it as needed.",
  "comprehensive_score_weight_sum": "Total weight:",
  "intelligent_generation_dataset": "Auto generate dataset",
  "dataset_name_input": "Name",
  "dataset_name_input_placeholder": "Dataset name",
  "generation_basis": "Data source",
  "select_knowledge_base": "Select knowledge base",
  "data_amount": "Data size",
  "generation_model": "Model",
  "generation_model_placeholder": "Select",
  "high_quality": "High quality",
  "needs_improvement": "Pending optimization",
  "detail_evaluating": "Evaluating",
  "abnormal": "Evaluation error",
  "not_evaluated": "Not evaluated",
  "modify_result": "Modify",
  "restart_evaluation": "Evaluate again",
  "evaluation_error_message": "Error occurred during the evaluation. Please try again.",
  "high_quality_feedback": "The question is complete and clear, meeting the standard. The answer is accurate and practical.",
  "needs_improvement_feedback": "The question needs to be optimized. To obtain a more accurate answer, please provide more context to make the question more specific and clear.",
  "evaluation_service_error": "Evaluation encountered error.",
  "edit_data": "Edit data",
  "enter_question": "",
  "question_required": "Question is required.",
  "reference_answer": "Answer for reference",
  "enter_reference_answer": "",
  "reference_answer_required": "Answer for reference is required.",
  "quality_evaluation": "Auto quality evaluation",
  "cancel": "Cancel",
  "save": "Save",
  "save_and_next": "Save and proceed",
  "manually_calibrated": "Results modified manually.",
  "modify_evaluation_result_title": "Modify result",
  "evaluation_result_label": "Evaluation result",
  "modify_reason_label": "Reason",
  "modify_reason_input_placeholder": "Reason",
  "no_data": "No data available.",
  "search": "Search",
  "settings": "Settings",
  "add_data": "Add data",
  "ai_generate": "Auto generate",
  "manual_add": "Manually add",
  "no_answer": "No answers available.",
  "confirm_delete_data": "Are you sure you want to delete this entry?",
  "no_evaluation_result_click": "No evaluation results available. ",
  "start_evaluation_action": "start evaluation.",
  "evaluation_dataset": "Dataset",
  "evaluation_status": "Status",
  "manually_add_data_modal": "Add data manually",
  "question_input_label": "Question",
  "max_chars_3000_placeholder": "Maximum: 3,000 characters",
  "reference_answer_input_label": "Answer for reference",
  "auto_quality_eval_after_add": "Data quality evaluation",
  "auto_quality_eval_add_tip": "If enabled, Q&A relevance and correctness are automatically evaluated, with quality feedback for optimization.",
  "quality_eval_model_label": "Quality evaluation model",
  "select_quality_eval_model_placeholder": "Select",
  "confirm": "OK",
  "confirm_quality_evaluation": "Are you sure you want to evaluate the quality of all data ({{total}})?",
  "model_change_notice": "Changing the model will apply to subsequent tasks.",
  "evaluation_model": "Model",
  "select_evaluation_model": "Select",
  "evaluation_abnormal": "Evaluation error",
  "error_message": "Error message",
  "file_parse_error": "File parsing error",
  "delete_file": "Delete file",
  "reparse": "Reparse",
  "data_generation_error": "Generation error",
  "source_knowledge_base": "Based on knowledge base",
  "source_chunk": "Based on chunk",
  "operations": "Operation",
  "retry": "Retry",
  "retry_all": "Retry all",
  "error_info": "Error",
  "manual_add_data": "Add data manually",
  "max_3000_chars": "Maximum: 3,000 characters",
  "please_enter_question": "",
  "question_max_3000_chars": "Cannot exceed 3,000 characters.",
  "please_enter_reference_answer": "",
  "reference_answer_max_3000_chars": "Cannot exceed 3,000 characters.",
  "auto_quality_evaluation": "Automatically evaluate data quality of the added data.",
  "quality_evaluation_tip": "Q&A relevance and correctness are automatically evaluated, with quality feedback for optimization.",
  "quality_evaluation_model": "Quality evaluation model",
  "please_select_evaluation_model": "Select",
  "summary_pending": "To be generated",
  "summary_generating": "Generating",
  "summary_done": "Completed",
  "summary_failed": "Failed",
  "method_mean": "Average",
  "method_median": "Median",
  "prompt_cannot_be_empty": "Prompt is required.",
  "please_select_model": "Please select a model.",
  "run_failed_please_retry": "Failed to run. Please try again.",
  "intelligent_generate_data": "Auto generate data",
  "evaluation_completed": "Evaluation completed.",
  "generation_error": "Generation error",
  "data_generating": "Generating data",
  "delete_dataset_error": "Error occurred while deleting dataset.",
  "create_failed": "Creation failed.",
  "no_dimension_data": "No metric data available.",
  "please_select_dimension_first": "Please select the metric first.",
  "model_evaluation_tip": "The language model determines whether the actual answer and the answer for reference match. The index model converts the actual and reference answers into vectors to further evaluate semantic similarity.",
  "create_new_dimension": "Add metric",
  "retry_success": "Retry successfully",
  "data_generation_error_count": "{{count}} pieces of data generated exception",
  "builtin_answer_correctness_name": "Answer Correctness",
  "builtin_answer_correctness_desc": "Evaluates the factual consistency between the generated answer and the reference answer, evaluating whether it is accurate and error-free.",
  "builtin_answer_similarity_name": "Answer Similarity",
  "builtin_answer_similarity_desc": "Evaluates the semantic alignment between the generated answer and the reference answer, determining whether they convey the same core information.",
  "builtin_answer_relevancy_name": "Answer Relevance",
  "builtin_answer_relevancy_desc": "Evaluates how well the generated answer aligns with the question, judging whether the response directly addresses the query.",
  "builtin_faithfulness_name": "Faithfulness",
  "builtin_faithfulness_desc": "Evaluates whether the generated answer remains faithful to the provided context, determining whether it contains fabricated or inaccurate content.",
  "builtin_context_recall_name": "Context Recall",
  "builtin_context_recall_desc": "Evaluates whether the retrieval system successfully retrieves all key information necessary for formulating the answer, assessing the completeness of retrieval.",
  "builtin_context_precision_name": "Context Precision",
  "builtin_context_precision_desc": "Evaluates whether high-value information is prioritized in the retrieved content, reflecting the quality of ranking and information density.",
  "join_evaluation_dataset": "Add to dataset",
  "not_join_evaluation_dataset": "Do not add to dataset",
  "create_new_dataset_btn_text": "Add to dataset",
  "please_select_evaluation_dataset": "Select",
  "join_knowledge_base": "Add to knowledge base",
  "all_data_with_count": "All data ({{num}}）",
  "question_data_with_count": "Problem data（{{num}}）",
  "error_data_with_count": "Error data（{{num}}）",
  "export_data": "Export",
  "retry_action": "Retry",
  "basic_info": "Basics",
  "application": "App",
  "version": "Version",
  "evaluation_dataset_name": "Datasets",
  "start_time": "Start time",
  "end_time": "End time",
  "executor_name": "Operator",
  "app_with_search_and_chat_recommendation": "评测应用包含知识库搜索和AI对话环节，已推荐使用 3 个维度进行评估",
  "app_with_chat_recommendation": "评测应用包含AI对话环节，已推荐使用 1 个维度进行评估",
  "app_with_search_recommendation": "评测应用包含知识库搜索环节，已推荐使用 2 个维度进行评估",
  "no_dimensions_added": "还没有添加评测维度，",
  "click_to_add": "点击添加",
  "meets_expectation": "符合预期！",
  "below_expectation": "低于预期分数！",
  "summary_generation_error": "总结内容生成异常，",
  "error_message_prefix": "报错信息：",
  "summary_pending_generation": "总结内容待生成",
  "summary_generating_content": "总结内容生成中",
  "data_with_count": "数据（{{data}}）",
  "search_placeholder": "搜索",
  "detail_title": "详情",
  "modify_dataset_simultaneously": "同时修改评测数据集",
  "retry_button": "重试",
  "edit_action": "编辑",
  "delete_action": "删除",
  "confirm_delete_data_in_task": "确认在当前任务中删除该数据？",
  "view_full_response": "查看完整响应",
  "abnormal_status": "异常",
  "question_field": "问题",
  "reference_answer_field": "参考答案",
  "actual_answer_field": "实际回答",
  "no_answer_available": "暂无回答",
  "comprehensive_score_title": "综合评分",
  "dimension_score_title": "维度评分",
  "error_data_calculation_notice": "{{count}} 条数据执行异常，仅使用执行成功的数据来计算分数。",
  "regenerate_summary_content": "重新生成总结内容",
  "processing_status": "处理中...",
  "view_results_after_completion": "完成后可查看评测结果",
  "all_data_execution_error": "全部数据执行异常，",
  "check_error_details": "请查看异常数据中的详细原因，",
  "click_to_retry": "点击重试",
  "comprehensive_score_weight_description": "按照指定权重计算测试数据全部维度的综合评分，可根据应用使用场景所关注的维度进行设置。",
  "no_data_available": "暂无数据",
  "question_column": "问题", 
  "comprehensive_score_column": "综合评分",
  "error_info_column": "异常信息",
  "request_failed": "请求失败",
  "retry_request_submitted": "重试请求已提交",
  "retry_failed": "重试失败",
  "save_success": "保存成功",
  "save_failed": "保存失败",
  "summary_generation_request_submitted": "总结生成请求已提交",
  "generate_summary_failed": "生成总结失败",
  "export_failed": "导出失败",
  "load_failed": "加载失败",
  "export_success": "导出成功",
  "no_dimension_data_cannot_generate_summary": "暂无维度数据，无法生成总结"
}
